{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports and Constants\n",
    "- Select user before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-26T14:09:29.637391056Z",
     "start_time": "2023-06-26T14:09:26.073235968Z"
    }
   },
   "outputs": [],
   "source": [
    "############## AUTORELOAD MAGIC ###################\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "###################################################\n",
    "\n",
    "############## FUNDAMENTAL MODULES ################\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " ##################################################\n",
    "\n",
    "############## TASK-SPECIFIC MODULES ##############\n",
    "sys.path.append(os.path.join(os.getcwd(),\"src\"))\n",
    "from vanilla_dataset import VanillaDataset\n",
    "from vanilla_nn import VanillaNN\n",
    "from trainer import Trainer\n",
    "from eval import evaluate_model, write_eval_to_file, pretty_print_metrics, cross_validate_thresholds\n",
    "###################################################\n",
    "\n",
    "\n",
    "####################### CONSTANTS ########################\n",
    "SPLITS = [\"train\", \"dev\", \"test\", \"gold\"]\n",
    "TRAIN, DEV, TEST, TXT, IMG = \"train\", \"dev\", \"test\", \"txt\", \"img\"\n",
    "FE_METHODS = [\"txt_embeddings\", \"img_embeddings\", \"concat\", \"sum\", \"mean\", \"hadamard\"]\n",
    "GOLD = \"gold\"\n",
    "RANDOM_SEED = 42\n",
    "#FE_METHODS += [\"concat_cos\", \"sum_cos\", \"mean_cos\", \"hadamard_cos\"]\n",
    "##########################################################\n",
    "\n",
    "############## DATA SCIENCE & ML MODULES #################\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
    "import torch\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "##########################################################\n",
    "\n",
    "####################### SELECT ###########################\n",
    "users = [\"patriziopalmisano\", \"onurdenizguler\", \"jockl\"]\n",
    "user = users[2] # SELECT USER\n",
    "version = \"v2\" # SELECT DATASET VERSION\n",
    "dataset_version = version\n",
    "##########################################################\n",
    "\n",
    "if user in users[:2]:\n",
    "    data_dir = f\"/Users/{user}/Library/CloudStorage/GoogleDrive-check.worthiness@gmail.com/My Drive/data/CT23_1A_checkworthy_multimodal_english_{version}\"\n",
    "    cw_dir = f\"/Users/{user}/Library/CloudStorage/GoogleDrive-check.worthiness@gmail.com/My Drive\"\n",
    "\n",
    "else:\n",
    "    data_dir = f\"/home/jockl/Insync/check.worthiness@gmail.com/Google Drive/data/CT23_1A_checkworthy_multimodal_english_{dataset_version}\"\n",
    "    cw_dir = \"/home/jockl/Insync/check.worthiness@gmail.com/Google Drive\"\n",
    "\n",
    "features_dir = f\"{data_dir}/features\"\n",
    "labels_dir = f\"{data_dir}/labels\"\n",
    "models_dir = f\"{cw_dir}/models/vanillann_hyperparam_search\"\n",
    "evals_dir = f\"{models_dir}/threshold_cross_validation\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:09:59.098632013Z",
     "start_time": "2023-06-26T14:09:58.821278339Z"
    }
   },
   "outputs": [],
   "source": [
    "split_to_labels = {split: \n",
    "                        np.load(f\"{labels_dir}/{split}_labels_{dataset_version}.pickle\", allow_pickle=True) if split != \"gold\" else \n",
    "                        np.load(f\"{labels_dir}/{split}_labels.pickle\", allow_pickle=True)\n",
    "                for split in SPLITS}\n",
    "\n",
    "method_to_split_to_data = {fe_method: {\n",
    "                                split: \n",
    "                                        np.load(f\"{features_dir}/{fe_method}/{fe_method}_{split}_{dataset_version}.pickle\", allow_pickle=True) if split != \"gold\" else \n",
    "                                        np.load(f\"{features_dir}/{fe_method}/{fe_method}_{split}.pickle\", allow_pickle=True)\n",
    "                                for split in SPLITS} \n",
    "                        for fe_method in FE_METHODS}\n",
    "\n",
    "method_to_split_to_dataset = {fe_method: {\n",
    "                                split:\n",
    "                                        VanillaDataset(method_to_split_to_data[fe_method][split], split_to_labels[split]) \n",
    "                                for split in SPLITS} \n",
    "                        for fe_method in FE_METHODS}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cross-Validation of Best Models\n",
    "\n",
    "In this section, we cross-validate those models that yielded the best validation accuracy within training. We cross-validate the best model for the following feature methods respectively:\n",
    "\n",
    "- Txt Embeddings\n",
    "- Concat Features\n",
    "- Mean Features\n",
    "\n",
    "Those best models come from the runs saved and TensorBoard-logged under\n",
    "\n",
    "- \"prototyping/CIMC-XX_hyperparam-search-vanillann/runs\".\n",
    "\n",
    "The aim of the cross-validation is to optimize our models' prediction thresholds. The default prediction threshold the models were trained on is 0.5. Given the class imbalance of our dataset, however, it is reasonable to check if other thresholds perform better. Hence, the following routine is performed for every considered model:\n",
    "\n",
    "- For all k cross-validation splits, the model is evaluated on different thresholds.\n",
    "- We keep the best performing threshold for each of the splits folds.\n",
    "- We mean over all the k best thresholds -> This is the final best threshold.\n",
    "\n",
    "Finally:\n",
    "\n",
    "- Every model (with its best threshold according to cross-val) is evaluated on the gold test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:01.742081566Z",
     "start_time": "2023-06-26T14:10:01.656258752Z"
    }
   },
   "outputs": [],
   "source": [
    "# Used for every cross-validation\n",
    "k = 6\n",
    "thresholds = np.array(range(10, 60, 5)) / 100\n",
    "shuffle = True\n",
    "output_dim = [1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Txt Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:04.440362010Z",
     "start_time": "2023-06-26T14:10:04.397733969Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set feature method, best model name, batch size, hidden dims\n",
    "feature_method = \"txt_embeddings\"\n",
    "model_name = \"13-06-2023_01-03_txt_embeddings_32x16_lr_1e-05_batch-size_16_shuffled_f1_0.76\"\n",
    "batch_size = 16\n",
    "hidden_dims = [32, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:06.040782739Z",
     "start_time": "2023-06-26T14:10:05.990192624Z"
    }
   },
   "outputs": [],
   "source": [
    "# File to store eval data\n",
    "eval_file = f\"{evals_dir}/{feature_method}/{k}_fold_{model_name}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:06.742916966Z",
     "start_time": "2023-06-26T14:10:06.680178247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 2356\n",
      "Number of dev examples: 271\n",
      "Number of cross-val examples: 2627\n"
     ]
    }
   ],
   "source": [
    "# Create cross-validation dataset\n",
    "train_dataset = method_to_split_to_dataset[feature_method][TRAIN]\n",
    "dev_dataset = method_to_split_to_dataset[feature_method][DEV]\n",
    "cross_val_dataset = ConcatDataset([train_dataset, dev_dataset])\n",
    "splits = KFold(n_splits=k, shuffle=shuffle, random_state=RANDOM_SEED)\n",
    "\n",
    "# Inspect datasets\n",
    "print(f\"Number of train examples: {len(train_dataset)}\")\n",
    "print(f\"Number of dev examples: {len(dev_dataset)}\")\n",
    "print(f\"Number of cross-val examples: {len(cross_val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:08.457531632Z",
     "start_time": "2023-06-26T14:10:08.326411300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VanillaNN(\n  (sequence): Sequential(\n    (0): Linear(in_features=768, out_features=32, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=32, out_features=16, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=16, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model_dir = f\"{models_dir}/{feature_method}/{model_name}.pt\"\n",
    "input_dim = [len(cross_val_dataset[0][0])]\n",
    "init_params = input_dim + hidden_dims + output_dim\n",
    "model = VanillaNN(init_params)\n",
    "model.load_state_dict(torch.load(model_dir))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:12.193815472Z",
     "start_time": "2023-06-26T14:10:09.383295241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best on fold 0: Threshold=0.3\n",
      "0.0: {'precision': 0.9125, 'recall': 0.8295454545454546, 'f1-score': 0.869047619047619, 'support': 264}\n",
      "1.0: {'precision': 0.7727272727272727, 'recall': 0.8793103448275862, 'f1-score': 0.8225806451612904, 'support': 174}\n",
      "accuracy: 0.8493150684931506\n",
      "\n",
      "Best on fold 1: Threshold=0.35\n",
      "0.0: {'precision': 0.9221789883268483, 'recall': 0.8172413793103448, 'f1-score': 0.8665447897623401, 'support': 290}\n",
      "1.0: {'precision': 0.7071823204419889, 'recall': 0.8648648648648649, 'f1-score': 0.778115501519757, 'support': 148}\n",
      "accuracy: 0.8333333333333334\n",
      "\n",
      "Best on fold 2: Threshold=0.45\n",
      "0.0: {'precision': 0.8829787234042553, 'recall': 0.89568345323741, 'f1-score': 0.8892857142857142, 'support': 278}\n",
      "1.0: {'precision': 0.8141025641025641, 'recall': 0.79375, 'f1-score': 0.8037974683544304, 'support': 160}\n",
      "accuracy: 0.8584474885844748\n",
      "\n",
      "Best on fold 3: Threshold=0.3\n",
      "0.0: {'precision': 0.9540229885057471, 'recall': 0.7955271565495208, 'f1-score': 0.867595818815331, 'support': 313}\n",
      "1.0: {'precision': 0.6384180790960452, 'recall': 0.904, 'f1-score': 0.7483443708609271, 'support': 125}\n",
      "accuracy: 0.8264840182648402\n",
      "\n",
      "Best on fold 4: Threshold=0.4\n",
      "0.0: {'precision': 0.9348659003831418, 'recall': 0.856140350877193, 'f1-score': 0.8937728937728938, 'support': 285}\n",
      "1.0: {'precision': 0.768361581920904, 'recall': 0.8888888888888888, 'f1-score': 0.8242424242424243, 'support': 153}\n",
      "accuracy: 0.867579908675799\n",
      "\n",
      "Best on fold 5: Threshold=0.45\n",
      "0.0: {'precision': 0.9217081850533808, 'recall': 0.8931034482758621, 'f1-score': 0.9071803852889667, 'support': 290}\n",
      "1.0: {'precision': 0.8012820512820513, 'recall': 0.8503401360544217, 'f1-score': 0.8250825082508251, 'support': 147}\n",
      "accuracy: 0.8787185354691075\n",
      "\n",
      "Mean of best thresholds: 0.375\n",
      "Mean of best f1-scores: 0.8003604863982758\n"
     ]
    }
   ],
   "source": [
    "# Collect best f1 score and corresponding threshold for every split\n",
    "report_string, mean_best_threshold = cross_validate_thresholds(model=model, cross_val_dataset=cross_val_dataset, splits=splits, thresholds=thresholds, batch_size=batch_size)\n",
    "print(report_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE ON GOLD SET\n",
      "Threshold=0.375\n",
      "0.0: {'precision': 0.8032786885245902, 'recall': 0.8540305010893247, 'f1-score': 0.8278775079197466, 'support': 459}\n",
      "1.0: {'precision': 0.7298387096774194, 'recall': 0.6534296028880866, 'f1-score': 0.6895238095238094, 'support': 277}\n",
      "accuracy: 0.7785326086956522\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best threshold on gold\n",
    "eval_dataset = method_to_split_to_dataset[feature_method][GOLD]\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "metrics_dict = evaluate_model(model=model, dataloader=eval_dataloader, confidence=mean_best_threshold)\n",
    "\n",
    "# Print and save results\n",
    "gold_result_string = f\"PERFORMANCE ON GOLD SET\\n{pretty_print_metrics(metrics_dict, mean_best_threshold)}\"\n",
    "report_string += f\"\\n\\n{gold_result_string}\"\n",
    "write_eval_to_file(file_path=eval_file, report_string=report_string)\n",
    "print(gold_result_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:12.393487645Z",
     "start_time": "2023-06-26T14:10:12.199712776Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Concat Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:12.417712358Z",
     "start_time": "2023-06-26T14:10:12.330950098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set feature method, model name, batch size, hidden dims\n",
    "feature_method = \"concat\"\n",
    "model_name = \"13-06-2023_03-03_concat_128x64x32_lr_0.0001_batch-size_64_shuffled_f1_0.75\"\n",
    "batch_size = 64\n",
    "hidden_dims = [128, 64, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:12.421279416Z",
     "start_time": "2023-06-26T14:10:12.374083967Z"
    }
   },
   "outputs": [],
   "source": [
    "# File to store eval data\n",
    "eval_file = f\"{evals_dir}/{feature_method}/{k}_fold_{model_name}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:12.604584665Z",
     "start_time": "2023-06-26T14:10:12.533653887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 2356\n",
      "Number of dev examples: 271\n",
      "Number of cross-val examples: 2627\n"
     ]
    }
   ],
   "source": [
    "# Create cross-validation dataset\n",
    "train_dataset = method_to_split_to_dataset[feature_method][TRAIN]\n",
    "dev_dataset = method_to_split_to_dataset[feature_method][DEV]\n",
    "cross_val_dataset = ConcatDataset([train_dataset, dev_dataset])\n",
    "splits = KFold(n_splits=k, shuffle=shuffle, random_state=RANDOM_SEED)\n",
    "\n",
    "# Inspect datasets\n",
    "print(f\"Number of train examples: {len(train_dataset)}\")\n",
    "print(f\"Number of dev examples: {len(dev_dataset)}\")\n",
    "print(f\"Number of cross-val examples: {len(cross_val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:13.388254808Z",
     "start_time": "2023-06-26T14:10:13.322416897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VanillaNN(\n  (sequence): Sequential(\n    (0): Linear(in_features=1536, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=32, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model_dir = f\"{models_dir}/{feature_method}/{model_name}.pt\"\n",
    "input_dim = [len(cross_val_dataset[0][0])]\n",
    "init_params = input_dim + hidden_dims + output_dim\n",
    "model = VanillaNN(init_params)\n",
    "model.load_state_dict(torch.load(model_dir))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:15.862476158Z",
     "start_time": "2023-06-26T14:10:13.640052857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best on fold 0: Threshold=0.45\n",
      "0.0: {'precision': 0.9581749049429658, 'recall': 0.9545454545454546, 'f1-score': 0.9563567362428842, 'support': 264}\n",
      "1.0: {'precision': 0.9314285714285714, 'recall': 0.9367816091954023, 'f1-score': 0.9340974212034384, 'support': 174}\n",
      "accuracy: 0.9474885844748858\n",
      "\n",
      "Best on fold 1: Threshold=0.5\n",
      "0.0: {'precision': 0.9423728813559322, 'recall': 0.9586206896551724, 'f1-score': 0.9504273504273504, 'support': 290}\n",
      "1.0: {'precision': 0.916083916083916, 'recall': 0.8851351351351351, 'f1-score': 0.9003436426116838, 'support': 148}\n",
      "accuracy: 0.9337899543378996\n",
      "\n",
      "Best on fold 2: Threshold=0.5\n",
      "0.0: {'precision': 0.950354609929078, 'recall': 0.9640287769784173, 'f1-score': 0.9571428571428572, 'support': 278}\n",
      "1.0: {'precision': 0.9358974358974359, 'recall': 0.9125, 'f1-score': 0.9240506329113924, 'support': 160}\n",
      "accuracy: 0.9452054794520548\n",
      "\n",
      "Best on fold 3: Threshold=0.35\n",
      "0.0: {'precision': 0.9796610169491525, 'recall': 0.9233226837060703, 'f1-score': 0.9506578947368421, 'support': 313}\n",
      "1.0: {'precision': 0.8321678321678322, 'recall': 0.952, 'f1-score': 0.8880597014925373, 'support': 125}\n",
      "accuracy: 0.9315068493150684\n",
      "\n",
      "Best on fold 4: Threshold=0.45\n",
      "0.0: {'precision': 0.9616724738675958, 'recall': 0.968421052631579, 'f1-score': 0.965034965034965, 'support': 285}\n",
      "1.0: {'precision': 0.9403973509933775, 'recall': 0.9281045751633987, 'f1-score': 0.9342105263157895, 'support': 153}\n",
      "accuracy: 0.954337899543379\n",
      "\n",
      "Best on fold 5: Threshold=0.55\n",
      "0.0: {'precision': 0.96875, 'recall': 0.9620689655172414, 'f1-score': 0.9653979238754326, 'support': 290}\n",
      "1.0: {'precision': 0.9261744966442953, 'recall': 0.9387755102040817, 'f1-score': 0.9324324324324326, 'support': 147}\n",
      "accuracy: 0.954233409610984\n",
      "\n",
      "Mean of best thresholds: 0.4666666666666666\n",
      "Mean of best f1-scores: 0.9188657261612123\n"
     ]
    }
   ],
   "source": [
    "# Collect best f1 score and corresponding threshold for every split\n",
    "report_string, mean_best_threshold = cross_validate_thresholds(model=model, cross_val_dataset=cross_val_dataset, splits=splits, thresholds=thresholds, batch_size=batch_size)\n",
    "print(report_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE ON GOLD SET\n",
      "Threshold=0.4666666666666666\n",
      "0.0: {'precision': 0.8047808764940239, 'recall': 0.8801742919389978, 'f1-score': 0.8407908428720082, 'support': 459}\n",
      "1.0: {'precision': 0.7649572649572649, 'recall': 0.6462093862815884, 'f1-score': 0.700587084148728, 'support': 277}\n",
      "accuracy: 0.7921195652173914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best threshold on gold\n",
    "eval_dataset = method_to_split_to_dataset[feature_method][GOLD]\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "metrics_dict = evaluate_model(model=model, dataloader=eval_dataloader, confidence=mean_best_threshold)\n",
    "\n",
    "# Print and save results\n",
    "gold_result_string = f\"PERFORMANCE ON GOLD SET\\n{pretty_print_metrics(metrics_dict, mean_best_threshold)}\"\n",
    "report_string += f\"\\n\\n{gold_result_string}\"\n",
    "write_eval_to_file(file_path=eval_file, report_string=report_string)\n",
    "print(gold_result_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:16.001055800Z",
     "start_time": "2023-06-26T14:10:15.866293116Z"
    }
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Mean Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:16.113187207Z",
     "start_time": "2023-06-26T14:10:15.973367770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set feature method, model name, batch size, hidden dims\n",
    "feature_method = \"mean\"\n",
    "model_name = \"13-06-2023_05-33_mean_128x64x32x16_lr_0.001_batch-size_8_shuffled_f1_0.71\"\n",
    "batch_size = 8\n",
    "hidden_dims = [128, 64, 32, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:16.167475231Z",
     "start_time": "2023-06-26T14:10:16.024320348Z"
    }
   },
   "outputs": [],
   "source": [
    "# File to store eval data\n",
    "eval_file = f\"{evals_dir}/{feature_method}/{k}_fold_{model_name}.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:16.168911507Z",
     "start_time": "2023-06-26T14:10:16.073438754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train examples: 2356\n",
      "Number of dev examples: 271\n",
      "Number of cross-val examples: 2627\n"
     ]
    }
   ],
   "source": [
    "# Create cross-validation dataset\n",
    "train_dataset = method_to_split_to_dataset[feature_method][TRAIN]\n",
    "dev_dataset = method_to_split_to_dataset[feature_method][DEV]\n",
    "#gold_dataset = method_to_split_to_dataset[feature_method][DEV]\n",
    "cross_val_dataset = ConcatDataset([train_dataset, dev_dataset])\n",
    "splits = KFold(n_splits=k, shuffle=shuffle, random_state=RANDOM_SEED)\n",
    "\n",
    "# Inspect datasets\n",
    "print(f\"Number of train examples: {len(train_dataset)}\")\n",
    "print(f\"Number of dev examples: {len(dev_dataset)}\")\n",
    "print(f\"Number of cross-val examples: {len(cross_val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:16.295450445Z",
     "start_time": "2023-06-26T14:10:16.165485732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VanillaNN(\n  (sequence): Sequential(\n    (0): Linear(in_features=768, out_features=128, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=128, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=32, bias=True)\n    (5): ReLU()\n    (6): Linear(in_features=32, out_features=16, bias=True)\n    (7): ReLU()\n    (8): Linear(in_features=16, out_features=1, bias=True)\n  )\n)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model_dir = f\"{models_dir}/{feature_method}/{model_name}.pt\"\n",
    "input_dim = [len(cross_val_dataset[0][0])]\n",
    "init_params = input_dim + hidden_dims + output_dim\n",
    "model = VanillaNN(init_params)\n",
    "model.load_state_dict(torch.load(model_dir))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:20.749610825Z",
     "start_time": "2023-06-26T14:10:17.271109905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best on fold 0: Threshold=0.55\n",
      "0.0: {'precision': 0.9879032258064516, 'recall': 0.928030303030303, 'f1-score': 0.9570312499999999, 'support': 264}\n",
      "1.0: {'precision': 0.9, 'recall': 0.9827586206896551, 'f1-score': 0.9395604395604396, 'support': 174}\n",
      "accuracy: 0.9497716894977168\n",
      "\n",
      "Best on fold 1: Threshold=0.5\n",
      "0.0: {'precision': 0.9819494584837545, 'recall': 0.9379310344827586, 'f1-score': 0.9594356261022928, 'support': 290}\n",
      "1.0: {'precision': 0.8881987577639752, 'recall': 0.9662162162162162, 'f1-score': 0.9255663430420712, 'support': 148}\n",
      "accuracy: 0.9474885844748858\n",
      "\n",
      "Best on fold 2: Threshold=0.55\n",
      "0.0: {'precision': 0.9925925925925926, 'recall': 0.9640287769784173, 'f1-score': 0.9781021897810218, 'support': 278}\n",
      "1.0: {'precision': 0.9404761904761905, 'recall': 0.9875, 'f1-score': 0.9634146341463415, 'support': 160}\n",
      "accuracy: 0.9726027397260274\n",
      "\n",
      "Best on fold 3: Threshold=0.45\n",
      "0.0: {'precision': 0.9931506849315068, 'recall': 0.9265175718849841, 'f1-score': 0.9586776859504132, 'support': 313}\n",
      "1.0: {'precision': 0.8424657534246576, 'recall': 0.984, 'f1-score': 0.9077490774907749, 'support': 125}\n",
      "accuracy: 0.9429223744292238\n",
      "\n",
      "Best on fold 4: Threshold=0.55\n",
      "0.0: {'precision': 0.9963235294117647, 'recall': 0.9508771929824561, 'f1-score': 0.9730700179533213, 'support': 285}\n",
      "1.0: {'precision': 0.9156626506024096, 'recall': 0.9934640522875817, 'f1-score': 0.9529780564263324, 'support': 153}\n",
      "accuracy: 0.9657534246575342\n",
      "\n",
      "Best on fold 5: Threshold=0.5\n",
      "0.0: {'precision': 0.9962264150943396, 'recall': 0.9103448275862069, 'f1-score': 0.9513513513513514, 'support': 290}\n",
      "1.0: {'precision': 0.8488372093023255, 'recall': 0.9931972789115646, 'f1-score': 0.9153605015673981, 'support': 147}\n",
      "accuracy: 0.9382151029748284\n",
      "\n",
      "Mean of best thresholds: 0.5166666666666667\n",
      "Mean of best f1-scores: 0.9341048420388929\n"
     ]
    }
   ],
   "source": [
    "# Collect best f1 score and corresponding threshold for every split\n",
    "report_string, mean_best_threshold = cross_validate_thresholds(model=model, cross_val_dataset=cross_val_dataset, splits=splits, thresholds=thresholds, batch_size=batch_size)\n",
    "print(report_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE ON GOLD SET\n",
      "Threshold=0.5166666666666667\n",
      "0.0: {'precision': 0.8302872062663186, 'recall': 0.6928104575163399, 'f1-score': 0.7553444180522565, 'support': 459}\n",
      "1.0: {'precision': 0.6005665722379604, 'recall': 0.7653429602888087, 'f1-score': 0.673015873015873, 'support': 277}\n",
      "accuracy: 0.720108695652174\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best threshold on gold\n",
    "eval_dataset = method_to_split_to_dataset[feature_method][GOLD]\n",
    "eval_dataloader = DataLoader(dataset=eval_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "metrics_dict = evaluate_model(model=model, dataloader=eval_dataloader, confidence=mean_best_threshold)\n",
    "\n",
    "# Print and save results\n",
    "gold_result_string = f\"PERFORMANCE ON GOLD SET\\n{pretty_print_metrics(metrics_dict, mean_best_threshold)}\"\n",
    "report_string += f\"\\n\\n{gold_result_string}\"\n",
    "write_eval_to_file(file_path=eval_file, report_string=report_string)\n",
    "print(gold_result_string)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-26T14:10:20.867246888Z",
     "start_time": "2023-06-26T14:10:20.753681203Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "cw1_new_kernel",
   "language": "python",
   "display_name": "cw1_new_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
